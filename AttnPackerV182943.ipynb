{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb545478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matthewmcpartlon /Users/matthewmcpartlon/VSCode/AttnPacker\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "code_root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if code_root not in sys.path:\n",
    "    sys.path.append(code_root)\n",
    "print(code_root,os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8c3345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmcpartlon/miniconda3/envs/attnpacker/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from protein_learning.models.inference_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da3e0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] : no value for key help, arg_group : optional arguments\n",
      "[INFO] adding embeddings for res_ty: [1]\n",
      "[INFO] adding embeddings for rel_pos: [1]\n",
      "[INFO] adding embeddings for bb_dihedral: [1]\n",
      "[INFO] adding embeddings for centrality: [0]\n",
      "[INFO] adding embeddings for rel_sep: []\n",
      "[INFO] adding embeddings for rel_dist: [0]\n",
      "[INFO] adding embeddings for tr_ori: [1]\n",
      "[INFO] adding embeddings for rel_chain: [1]\n",
      "------------------------------------------------------\n",
      "[INFO] Input feature embeddings\n",
      "\n",
      "----[INFO] SCALAR (dim = 115)\n",
      "\n",
      "--------res_ty\n",
      "------------one_hot : 23\n",
      "--------rel_pos\n",
      "------------one_hot : 11\n",
      "--------bb_dihedral\n",
      "------------one_hot : 75\n",
      "--------centrality\n",
      "------------rbf : 6\n",
      "\n",
      "----[INFO] PAIR (dim = 205)\n",
      "\n",
      "--------rel_sep\n",
      "--------rel_dist\n",
      "------------rbf : 64\n",
      "--------tr_ori\n",
      "------------one_hot : 75\n",
      "--------rel_chain\n",
      "------------one_hot : 6\n",
      "--------joint_pair_n_sep\n",
      "------------rel_sep : 60\n",
      "------------res_ty_a : 60\n",
      "------------res_ty_b : 60\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "RESOURCE_ROOT = \"/Users/matthewmcpartlon/Downloads/fbb_design_ft_inference/models\"\n",
    "#MODEL_NAME = \"fbb_design_21_12_2022_16:00:06\" #RX7-1\n",
    "#MODEL_NAME = \"fbb_design_21_12_2022_15:57:43\" # RX11\n",
    "MODEL_NAME = \"fbb_design_21_12_2022_16:07:51\" #RX7-2\n",
    "runner = Inference(RESOURCE_ROOT, MODEL_NAME)\n",
    "model = runner.get_model()\n",
    "device = \"cpu\"#\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c03b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f8f94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmcpartlon/miniconda3/envs/attnpacker/lib/python3.8/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "pdb_path = \"/Users/matthewmcpartlon/Downloads/casp_all/T0967.pdb\"\n",
    "example = runner.load_example(pdb_path = pdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b756b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmcpartlon/miniconda3/envs/attnpacker/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran inference in 1.367 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    model_out = model.forward(example.to(device), use_cycles = 1)\n",
    "    print(f\"Ran inference in {round(time.time() - start,3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84527815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked residue positions\n",
    "seq_mask = default(\n",
    "    example.input_features.seq_mask,torch.zeros(len(example.decoy)).bool()\n",
    ")\n",
    "\n",
    "# coords, pLDDT, and Sequence\n",
    "res_feats = model_out.scalar_output\n",
    "pred_coords = model_out.predicted_coords\n",
    "pred_seq_labels = model_out.decoy_protein.seq_encoding\n",
    "pred_seq_logits = None\n",
    "\n",
    "\n",
    "# Predicted pLDDT\n",
    "plddt_head = model.loss_fn.loss_fns[\"plddt\"]\n",
    "pred_plddt = plddt_head.get_expected_value(res_feats)\n",
    "pred_plddt = pred_plddt\n",
    "\n",
    "# Predicted Sequence\n",
    "if \"nsr\" in model.loss_fn and torch.any(seq_mask):\n",
    "    pred_seq_logits = model.loss_fn.loss_fns[\"nsr\"].get_predicted_logits(res_feats)\n",
    "    pred_seq_labels = torch.argmax(pred_seq_logits,dim=-1)\n",
    "\n",
    "out = pred_coords, pred_seq_labels, pred_seq_logits, pred_plddt\n",
    "fn = lambda x : x.detach().cpu().squeeze() if torch.is_tensor(x) else x\n",
    "pred_coords, pred_seq_labels, pred_seq_logits, pred_plddt = map(fn,out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1626b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving pdb to ./attn_packer/examples/T0967_packed.pdb\n"
     ]
    }
   ],
   "source": [
    "pred_protein = make_predicted_protein(model_out, seq = pred_seq_labels)\n",
    "pdb_out_path = f\"./attn_packer/examples/{pred_protein.name}_packed.pdb\"\n",
    "print(f\"saving pdb to {pdb_out_path}\")\n",
    "pred_protein.to_pdb(pdb_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f77e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fn: project_onto_rotamers] : Using device cpu\n",
      "[INFO] Beginning rotamer projection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewmcpartlon/miniconda3/envs/attnpacker/lib/python3.8/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initial loss values\n",
      "   [RMSD loss] = 0.22\n",
      "   [Steric loss] = 0.026\n",
      "   [Angle Dev. loss] = 0.0\n",
      "\n",
      "beginning iter: 0, steric weight: 0.5\n",
      "beginning iter: 1, steric weight: 0.5\n",
      "[INFO] Final Loss Values\n",
      "   [RMSD loss] = 0.218\n",
      "   [Steric loss] = 0.024\n",
      "   [Angle Dev. loss] = 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from protein_learning.protein_utils.sidechains.project_sidechains import project_onto_rotamers\n",
    "\n",
    "pp_pdb_out_path = f\"./attn_packer/examples/{pred_protein.name}_packed_pp.pdb\"\n",
    "\n",
    "projected_coords, _ = project_onto_rotamers(\n",
    "    atom_coords = pred_protein.atom_coords.unsqueeze(0),\n",
    "    sequence = pred_protein.seq_encoding.unsqueeze(0),\n",
    "    atom_mask = pred_protein.atom_masks.unsqueeze(0),\n",
    "    steric_clash_weight=[0.5],\n",
    ")\n",
    "\n",
    "pred_protein.to_pdb(pp_pdb_out_path, coords=projected_coords.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866e1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558a1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
